{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVeErf4hu3a_"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision timm scikit-learn pandas numpy albumentations>=1.1.0\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.cuda.amp import GradScaler, autocast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set a seed for reproducibility across different runs\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "# Determine the device to use (GPU if available, otherwise CPU)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Define the number of cross-validation folds\n",
        "FOLDS = 5\n",
        "# Define the number of training epochs for each fold\n",
        "EPOCHS = 15\n",
        "# Define the batch size for training and validation data loaders\n",
        "BATCH_SIZE = 24\n",
        "# Define the image size for resizing\n",
        "IMG_SIZE = 416"
      ],
      "metadata": {
        "id": "VnoV59sftnWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data augmentation transformations for training\n",
        "train_aug = A.Compose([\n",
        "    # Randomly crop and resize the image\n",
        "    A.RandomResizedCrop(size=(IMG_SIZE, IMG_SIZE), scale=(0.8, 1.0)),\n",
        "    # Flip the image horizontally with a probability of 0.5\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    # Apply random shift, scale, and rotate transformations\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "    # Apply random color jitter\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
        "    # Apply CoarseDropout for regularization\n",
        "    A.CoarseDropout(max_holes=8, max_height=IMG_SIZE//20, max_width=IMG_SIZE//20, p=0.5),\n",
        "    # Normalize the image with specified mean and standard deviation\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    # Convert the image to a PyTorch tensor\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Define Test Time Augmentation (TTA) transformations\n",
        "def tta_transforms(image):\n",
        "    transforms = [\n",
        "        # Base transformation: resize and normalize\n",
        "        A.Compose([\n",
        "            A.Resize(height=IMG_SIZE, width=IMG_SIZE),\n",
        "            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "            ToTensorV2()\n",
        "        ]),\n",
        "        # Horizontal flip transformation: flip, resize and normalize\n",
        "        A.Compose([\n",
        "            A.HorizontalFlip(p=1.0),\n",
        "            A.Resize(height=IMG_SIZE, width=IMG_SIZE),\n",
        "            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "            ToTensorV2()\n",
        "        ]),\n",
        "    ]\n",
        "    # Apply transformations and return a list of augmented images\n",
        "    return [tr(image=image)['image'] for tr in transforms]"
      ],
      "metadata": {
        "id": "yY0ryHSTtyHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom dataset class for loading sheep images and labels\n",
        "class SheepDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transforms=None):\n",
        "        # Initialize the dataset with dataframe, image directory, and transformations\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transforms = transforms\n",
        "        # Create a mapping from label strings to integer indices\n",
        "        self.label_map = {lbl: idx for idx, lbl in enumerate(sorted(df['label'].unique()))}\n",
        "        # Create an inverse mapping from integer indices back to label strings\n",
        "        self.inv_map = {v: k for k, v in self.label_map.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of samples in the dataset\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get a sample from the dataset at the given index\n",
        "        row = self.df.iloc[idx]\n",
        "        # Load and convert the image to RGB format\n",
        "        img = np.array(Image.open(os.path.join(self.img_dir, row['filename'])).convert('RGB'))\n",
        "        # Apply transformations if any are defined\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)['image']\n",
        "        # Get the integer label using the label map\n",
        "        label = self.label_map[row['label']]\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "fn14lijut_J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Mixup data augmentation function\n",
        "def mixup_data(x, y, alpha=0.4):\n",
        "    # Generate a random lambda value from the Beta distribution\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "    # Get batch size and a random permutation of indices\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size).to(DEVICE)\n",
        "    # Create mixed images and labels\n",
        "    mixed_x = lam * x + (1 - lam) * x[index]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam"
      ],
      "metadata": {
        "id": "OoFggFnVuoSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the deep learning model\n",
        "def get_model(num_classes):\n",
        "    # Create an EfficientNet B5 model with specified number of output classes\n",
        "    model = timm.create_model(\n",
        "       \"hf_hub:timm/efficientnet_b5.sw_in12k\",\n",
        "        pretrained=True, # Load pre-trained weights\n",
        "        num_classes=num_classes, # Set the number of output classes\n",
        "        global_pool='avg' # Use average pooling\n",
        "    )\n",
        "    return model.to(DEVICE) # Move the model to the specified device\n",
        "\n",
        "# Define the loss function (Cross-Entropy Loss)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "71vWUT5uuzri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the model for one epoch\n",
        "def train_one_epoch(model, loader, optimizer, scaler):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    # Iterate over the data loader\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        # Apply Mixup to the data\n",
        "        images, y_a, y_b, lam = mixup_data(images, labels)\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Use automatic mixed precision for training\n",
        "        with autocast():\n",
        "            # Get model outputs\n",
        "            outputs = model(images)\n",
        "            # Calculate the Mixup loss\n",
        "            loss = lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)\n",
        "        # Scale the loss and perform backpropagation\n",
        "        scaler.scale(loss).backward()\n",
        "        # Update model weights\n",
        "        scaler.step(optimizer)\n",
        "        # Update the scaler for the next iteration\n",
        "        scaler.update()\n",
        "        # Accumulate the total loss\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "    # Return the average loss for the epoch\n",
        "    return total_loss / len(loader.dataset)"
      ],
      "metadata": {
        "id": "OWLDKSyMu6gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to validate the model\n",
        "def validate(model, loader):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    # Disable gradient calculation during validation\n",
        "    with torch.no_grad():\n",
        "        # Iterate over the validation data loader\n",
        "        for images, labels in loader:\n",
        "            images = images.to(DEVICE)\n",
        "            # Get model outputs\n",
        "            outputs = model(images)\n",
        "            # Get the predicted class with the highest probability\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            # Extend the lists of predictions and true labels\n",
        "            preds.extend(predicted.cpu().tolist())\n",
        "            trues.extend(labels.tolist())\n",
        "    # Calculate and return the weighted F1 score\n",
        "    return f1_score(trues, preds, average='weighted')"
      ],
      "metadata": {
        "id": "yFfpVyUEwchp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform cross-validation and calculate Out-of-Fold (OOF) predictions\n",
        "# Load the training labels\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/data/train_labels.csv')\n",
        "# Initialize an array to store OOF predictions\n",
        "oof_preds = np.zeros(len(train_df), dtype=int)\n",
        "# Set up StratifiedKFold for cross-validation\n",
        "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "# Iterate through each fold\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n",
        "    print(f\"\\n=== Fold {fold+1}/{FOLDS} ===\")\n",
        "    # Split the training data into training and validation sets for the current fold\n",
        "    df_train, df_val = train_df.iloc[train_idx], train_df.iloc[val_idx]\n",
        "\n",
        "    # Create training dataset with augmentations\n",
        "    train_set = SheepDataset(df_train, '/content/drive/MyDrive/data/train/', transforms=train_aug)\n",
        "    # Create validation dataset with standard transformations\n",
        "    val_set = SheepDataset(\n",
        "        df_val,\n",
        "        '/content/drive/MyDrive/data/train/',\n",
        "        transforms=A.Compose([\n",
        "            A.Resize(height=IMG_SIZE, width=IMG_SIZE),\n",
        "            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "    )\n",
        "    # Create data loaders for training and validation\n",
        "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Get the model, optimizer, learning rate scheduler, and GradScaler\n",
        "    model = get_model(len(train_set.label_map))\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, max_lr=3e-3, epochs=EPOCHS, steps_per_epoch=len(train_loader)\n",
        "    )\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # Initialize best F1 score for saving the best model\n",
        "    best_f1 = 0\n",
        "    # Train the model for the specified number of epochs\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        loss = train_one_epoch(model, train_loader, optimizer, scaler)\n",
        "        scheduler.step()\n",
        "        val_f1 = validate(model, val_loader)\n",
        "        print(f\"Epoch {epoch}: Loss={loss:.4f}, Val F1={val_f1:.4f}\")\n",
        "        # Save the model if the validation F1 score improves\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), f\"model_fold{fold}.pth\")\n",
        "    print(f\"Fold {fold+1} Best F1: {best_f1:.4f}\")\n",
        "\n",
        "    # Perform OOF predictions with Test Time Augmentation (TTA)\n",
        "    model.load_state_dict(torch.load(f\"model_fold{fold}.pth\"))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, row in enumerate(df_val.itertuples()):\n",
        "            # Load the image and apply TTA\n",
        "            img = np.array(Image.open(os.path.join('/content/drive/MyDrive/data/train/', row.filename)).convert('RGB'))\n",
        "            tts = tta_transforms(img)\n",
        "            # Get predictions for each TTA image and average them\n",
        "            outs = [model(t.unsqueeze(0).to(DEVICE)).softmax(1).cpu().numpy() for t in tts]\n",
        "            # Store the final OOF prediction for the current image\n",
        "            oof_preds[val_idx[idx]] = np.argmax(np.mean(outs, axis=0))"
      ],
      "metadata": {
        "id": "-TXpbB2802aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the overall Out-of-Fold (OOF) F1 score\n",
        "# Create the label map again for calculating OOF F1 score\n",
        "label_map = {lbl: idx for idx, lbl in enumerate(sorted(train_df['label'].unique()))}\n",
        "# Calculate the weighted F1 score using true labels and OOF predictions\n",
        "print(\"OOF F1:\", f1_score(train_df['label'].map(lambda x: label_map[x]), oof_preds, average='weighted'))"
      ],
      "metadata": {
        "id": "WmvFl7kB7BrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference on the test set and ensemble predictions from different folds\n",
        "# Create a dataframe of test filenames\n",
        "test_files = pd.DataFrame(os.listdir('/content/drive/MyDrive/data/test/'), columns=['filename'])\n",
        "# Initialize an array to store predictions for all test files\n",
        "all_preds = np.zeros((len(test_files), len(train_set.label_map)))\n",
        "\n",
        "# Iterate through each trained model from the cross-validation folds\n",
        "for fold in range(FOLDS):\n",
        "    # Get a new model and load the trained weights for the current fold\n",
        "    model = get_model(len(train_set.label_map))\n",
        "    model.load_state_dict(torch.load(f\"model_fold{fold}.pth\"))\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    # Disable gradient calculation during inference\n",
        "    with torch.no_grad():\n",
        "        # Iterate through each test file\n",
        "        for idx, fname in enumerate(test_files['filename']):\n",
        "            # Load the test image and apply TTA\n",
        "            img = np.array(Image.open(os.path.join('/content/drive/MyDrive/data/test/', fname)).convert('RGB'))\n",
        "            tts = tta_transforms(img)\n",
        "            # Get predictions for each TTA image and average them\n",
        "            outs = [model(t.unsqueeze(0).to(DEVICE)).softmax(1).cpu().numpy() for t in tts]\n",
        "            # Accumulate the averaged predictions for ensembling\n",
        "            all_preds[idx] += np.mean(outs, axis=0).flatten()\n",
        "\n",
        "# Average the predictions across all folds\n",
        "all_preds /= FOLDS\n",
        "# Get the predicted labels by taking the argmax of the ensembled predictions\n",
        "labels = [train_set.inv_map[np.argmax(p)] for p in all_preds]\n",
        "# Create the submission dataframe\n",
        "submission = pd.DataFrame({'filename': test_files['filename'], 'label': labels})\n",
        "# Save the submission file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Ensembled submission saved to submission_ensemble.csv\")"
      ],
      "metadata": {
        "id": "nWj98zwd62JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize predicted images from the test set\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a simple dataset class for displaying test images\n",
        "class SimpleTestDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transforms=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row['filename'])\n",
        "        img = np.array(Image.open(img_path).convert('RGB'))\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)['image']\n",
        "        return img, row['filename']\n",
        "\n",
        "# Create a dataframe with test filenames and predicted labels\n",
        "test_results_df = pd.DataFrame({'filename': test_files['filename'], 'predicted_label': labels})\n",
        "\n",
        "# Define transformations for displaying images\n",
        "display_transforms = A.Compose([\n",
        "    A.Resize(height=IMG_SIZE, width=IMG_SIZE),\n",
        "])\n",
        "\n",
        "# Create a dataset for displaying test images\n",
        "test_dataset_display = SimpleTestDataset(test_results_df, '/content/drive/MyDrive/data/test/', transforms=display_transforms)\n",
        "\n",
        "# --- Display Predicted Images ---\n",
        "\n",
        "# Function to display a grid of test images with predicted labels\n",
        "def display_predicted_images(dataset, results_df, num_rows=3, num_cols=10):\n",
        "    \"\"\"\n",
        "    Displays a few test images along with their predicted labels in a grid.\n",
        "    \"\"\"\n",
        "    num_images = num_rows * num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 3, num_rows * 3))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Select random indices for displaying images\n",
        "    display_indices = random.sample(range(len(dataset)), min(num_images, len(dataset)))\n",
        "\n",
        "    # Iterate through the selected indices and display images\n",
        "    for i, idx in enumerate(display_indices):\n",
        "        if i >= num_images:\n",
        "            break\n",
        "\n",
        "        img_tensor, filename = dataset[idx]\n",
        "\n",
        "        # Get the predicted label for the current image\n",
        "        predicted_label = results_df[test_results_df['filename'] == filename]['predicted_label'].iloc[0]\n",
        "\n",
        "        # Convert tensor to numpy array for display if needed\n",
        "        if isinstance(img_tensor, torch.Tensor):\n",
        "            img_display = img_tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "            # Load the original image to apply display transformations\n",
        "            original_img = np.array(Image.open(os.path.join(dataset.img_dir, filename)).convert('RGB'))\n",
        "            img_display = display_transforms(image=original_img)['image']\n",
        "\n",
        "        else:\n",
        "            img_display = img_tensor\n",
        "\n",
        "        # Display the image and set the title with the predicted label\n",
        "        axes[i].imshow(img_display)\n",
        "        axes[i].set_title(f\"Pred: {predicted_label}\")\n",
        "        axes[i].axis('off') # Hide axes\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    # Adjust layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to display predicted images\n",
        "display_predicted_images(test_dataset_display, test_results_df, num_rows=4, num_cols=10)"
      ],
      "metadata": {
        "id": "NCeaWs83Fsvw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}